{
    "block": [
        "{\"title\": \"untitled_block\", \"content\": \"Karthik Sanka\\nRaleigh, NC | ksanka@ncsu.edu | 984-377-0679 | https://www.linkedin.com/in/karthik-sanka-902224190/| https://github.com/Karthik2924\", \"link\": [415.92999267578125, 44.45001220703125, 521.5399780273438, 53.6500244140625]}",
        "{\"title\": \"EDUCATION\", \"content\": \"North Carolina State University, \\n \\n \\n \\n \\n \\n \\n \\n            \\n          Aug 2022 \\u2013 May2024\\nMaster of Computer Science | GPA \\u2013 4.0/4.0 \\nSRM Institute of Science and Technology, India \\n \\n \\n \\n \\n \\n \\n           Aug 2018 \\u2013 May 2022\\nBachelor of Technology in Computer Science & Engineering | GPA \\u2013 9.5 /10\\nRelevant Coursework: Machine Learning, Deep Learning, Efficient Neural Networks, Computer Vision, Data Analysis, Artificial Intelligence, \\nMachine Learning with Graphs, Linear Algebra, Calculus, Statistics, Probability, Data Structures and Algorithms, Object Oriented Design \\nTeaching assistant: Metaheuristics for search and optimization. Worked on different combinatorial optimization using heuristic algorithms for efficient \\nand tractable approximate solutions of problems otherwise intractable.\"}",
        "{\"title\": \"TECHNICAL SKILLS_\", \"content\": \"rogramming/Scripting Languages: Python, C++, Julia, R, SQL, BASH, LINUX \\nrameworks and Technologies: Deep Learning and distributed training : PyTorch, TensorFlow, Keras, Hugging Face; Data Analysis and Statistica\\nML : Pandas, sklearn; Visualization : plotly, matplotlib, tableau; NLP: spaCy, NLTK; Computer Vision : OpenCV; Generative AI: Autoregressive\\next(LLM) and Image, GAN, VAE, Efficient Model Inference: Knowledge Distillation, Pruning, Quantization; Docker, MapReduce Spark, AWS\"}",
        "{\"title\": \"EXPERIENCE\", \"content\": \"Graduate Research Assistant, North Carolina State University | Raleigh \\n \\n \\n \\n \\n          Aug 2023 \\u2013 Dec 2023\\n\\u2022 Conducted experiments on various representation learning and generative models such as VAEs and GANs. \\n\\u2022 Reproduced generative models on compressed representations from Vector Quantized Variational Autoencoders(VQVAE) and analyzed\\nvarious methods to disentangle different attributes of the data in latent space.\\n\\u2022 Proposed a new formulation of VQVAE to disentangle data using labels for just ~1% of the dataset and unsupervised fine tuning for the rest. \\n\\u2022 Achieved InfoM, InfoE, InfoC scores over 90 for 3 major benchmark disentanglement datasets. Research paper under review at UAI 2024.\\nMachine Learning Intern, Skylark Labs | USA-Remote  \\n \\n \\n \\n \\n \\n          Jun 2023 \\u2013 Aug 2023\\n\\u2022 Designed and developed a continual learning framework for object recognition from scratch using PyTorch. \\n\\u2022 Trained the framework to overcome catastrophic forgetting i.e learn new objects or samples while retaining the old ones.  \\n\\u2022 Utilized pretrained yolo-v8 for coarse grained object detection of generic objects and built a vector database for fine grained instances. \\n\\u2022 Improved the speed and efficiency of the vector database search by using approximate nearest neighbor search with FAISS.\\nResearch Intern, Samsung PRISM| India \\n \\n \\n \\n \\n \\n \\n                        Sep 2020 \\u2013 Mar 2021\\n\\u2022 Developed a hybrid sound classification engine using log-Mel audio features to detect artificial sounds as well as identify spoofed voice. \\n\\u2022 Trained a neural network using Residual Squeeze and excitation network. \\n\\u2022 Achieved an EER of 4.44 on the ASVSpoof2019 evaluation set. \\n\\u2022 Presented Research in ICCNT 2021 Conference. Paper Link\\nResearch Project Intern, National Institute of Ocean Technology| India.    \\n \\n \\n \\n                          Jan 2020 \\u2013 Mar 2021\\n\\u2022 Performed underwater image enhancement on deep sea images obtained by an ROV \\n\\u2022  Fine-tuned large deep learning models based on GAN FuNIE-GAN and convolutional neural networks UW-CNN to the small dataset available.\\nAlso implemented a physics based dehaze model for image enhancement using the popular Dark Channel Prior algorithm.\\n\\u2022 Made no reference image quality comparisons for all the different methods used and assessed runtimes to make recommendations.\\nAI Intern, Shunya OS/iotiot.in | India.    \\n \\n \\n \\n                           \\n \\n \\n            Jul 2020 \\u2013 Oct 2020\\n\\u2022 Designed and developed speech to text software which tackles speaker separation. \\n\\u2022 Used large open-source pre-trained speaker diarization model for speaker separation and DeepSpeech a speech to text model to build the pipeline.\", \"link\": [226.0, 410.1199951171875, 270.239990234375, 421.1199951171875]}",
        "{\"title\": \"PROJECTS\", \"content\": \"p\\np\\np\\np\\np\\np p\\np\\np p\\n________________________________________________________________________________________________ \\nContrastive Curriculum Augmentation Framework for Self-Supervised Learning (Group project, size 2)\\n\\u2022 Designed and implemented a novel contrastive self-supervised learning model with a curriculum augmentation framework. \\n\\u2022 Increased the difficulty of the images slowly with our framework by controlling the strengths of the augmentations during training. \\n\\u2022 Achieved improvement in accuracy by 15% from the baseline on CIFAR100 dataset. \\n\\u2022 Published our findings in IJSCAI. Paper Link\\nProbabilistic Graph Residual (Group project, size 2) Project Link\\n\\u2022 Developed a robust message passing framework for Graph Neural Networks which performs well for both normal and corrupted/noisy data.  \\n\\u2022 We efficiently compute KL Divergence between a node\\u2019s features and aggregated features from neighboring nodes in the same framework of\\nAPPNP and Adaptive message passing.\\n\\u2022 Our Graph Neural Network Mechanism achieves results comparable to the state -of-the-art performance reaching an accuracy of 84% on Cora,\\n83% on PubMed and 73% on CiteSeer datasets.\\nMotif Finding with Particle Swarm Optimization and DNA Sequence Preprocessing (Group project, size 2) Project Link\\n\\u2022 Developed a motif finding software framework using Particle Swarm Optimization to speed up the algorithm. Theoretical solution is often\\nintractable for large sequences as it is an NP Complete problem.\\n\\u2022 Results on both artificial sequences as well as real-world cotton fiber sequences show that our method can detect motifs outperforming other\\nexisting probabilistic methods such as MEME in terms of speed, albeit at the cost of accuracy. Won best poster award in the class for this project.\\nResidential Density and Slum Mapping from satellite images (Group project, size 3)\\n\\u2022 Curated a new dataset for housing density identification from various satellite image sources with slightly different modalities.  \\n\\u2022 Used unsupervised Domain Adaptation to train on multiple satellite image dataset NAIP and NWPU at the same time to detect residential\\ndensities and identify slums/informal settlements.\\n\\u2022 Achieved a high accuracy of 97% and 93% and NAIP and NWPU test set and 84% on UC Merced (completely out of distribution).\\nEXTRA CURRICULAR ACTIVITIES\", \"link\": [438.29998779296875, 646.2000122070312, 487.5400085449219, 656.5499877929688]}",
        "{\"title\": \"EXTRA-CURRICULAR ACTIVITIES_\", \"content\": \"\\u2022 Recon Subsea (Underwater Robotics Team Vice Lead): Worked on computer vision problems for underwater tasks such as template matching,\\nobject detection. Also built GUI for the ROV with camera feeds and various controls using PyQt.\"}"
    ]
}